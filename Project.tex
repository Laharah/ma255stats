\documentclass[11pt]{article}

    \usepackage[breakable]{tcolorbox}
    \usepackage{parskip} % Stop auto-indenting (to mimic markdown behaviour)
    

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % Maintain compatibility with old templates. Remove in nbconvert 6.0
    \let\Oldincludegraphics\includegraphics
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionFormat{nocaption}{}
    \captionsetup{format=nocaption,aboveskip=0pt,belowskip=0pt}

    \usepackage{float}
    \floatplacement{figure}{H} % forces figures to be placed at the correct location
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro

    \usepackage{iftex}
    \ifPDFTeX
        \usepackage[T1]{fontenc}
        \IfFileExists{alphabeta.sty}{
              \usepackage{alphabeta}
          }{
              \usepackage[mathletters]{ucs}
              \usepackage[utf8x]{inputenc}
          }
    \else
        \usepackage{fontspec}
        \usepackage{unicode-math}
    \fi

    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics
                         % to support a larger range
    \makeatletter % fix for old versions of grffile with XeLaTeX
    \@ifpackagelater{grffile}{2019/11/01}
    {
      % Do nothing on new versions
    }
    {
      \def\Gread@@xetex#1{%
        \IfFileExists{"\Gin@base".bb}%
        {\Gread@eps{\Gin@base.bb}}%
        {\Gread@@xetex@aux#1}%
      }
    }
    \makeatother
    \usepackage[Export]{adjustbox} % Used to constrain images to a maximum size
    \adjustboxset{max size={0.9\linewidth}{0.9\paperheight}}

    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    % The default LaTeX title has an obnoxious amount of whitespace. By default,
    % titling removes some of it. It also provides customization options.
    \usepackage{titling}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage{array}     % table support for pandoc >= 2.11.3
    \usepackage{calc}      % table minipage width calculation for pandoc >= 2.11.1
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    \usepackage{mathrsfs}
    

    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}
    \definecolor{ansi-default-inverse-fg}{HTML}{FFFFFF}
    \definecolor{ansi-default-inverse-bg}{HTML}{000000}

    % common color for the border for error outputs.
    \definecolor{outerrorbackground}{HTML}{FFDFDF}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}

    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}


    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatibility definitions
    \def\gt{>}
    \def\lt{<}
    \let\Oldtex\TeX
    \let\Oldlatex\LaTeX
    \renewcommand{\TeX}{\textrm{\Oldtex}}
    \renewcommand{\LaTeX}{\textrm{\Oldlatex}}
    % Document parameters
    % Document title
    \title{Project}
    
    
    
    
    
% Pygments definitions
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\@namedef{PY@tok@w}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\@namedef{PY@tok@c}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cp}{\def\PY@tc##1{\textcolor[rgb]{0.61,0.40,0.00}{##1}}}
\@namedef{PY@tok@k}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kt}{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\@namedef{PY@tok@o}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ow}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@nb}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nf}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@nn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@ne}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.80,0.25,0.22}{##1}}}
\@namedef{PY@tok@nv}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@no}{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\@namedef{PY@tok@nl}{\def\PY@tc##1{\textcolor[rgb]{0.46,0.46,0.00}{##1}}}
\@namedef{PY@tok@ni}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@na}{\def\PY@tc##1{\textcolor[rgb]{0.41,0.47,0.13}{##1}}}
\@namedef{PY@tok@nt}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@nd}{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\@namedef{PY@tok@s}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sd}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@si}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@se}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.36,0.12}{##1}}}
\@namedef{PY@tok@sr}{\def\PY@tc##1{\textcolor[rgb]{0.64,0.35,0.47}{##1}}}
\@namedef{PY@tok@ss}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sx}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@m}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@gh}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@gu}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\@namedef{PY@tok@gd}{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\@namedef{PY@tok@gi}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.52,0.00}{##1}}}
\@namedef{PY@tok@gr}{\def\PY@tc##1{\textcolor[rgb]{0.89,0.00,0.00}{##1}}}
\@namedef{PY@tok@ge}{\let\PY@it=\textit}
\@namedef{PY@tok@gs}{\let\PY@bf=\textbf}
\@namedef{PY@tok@gp}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\@namedef{PY@tok@go}{\def\PY@tc##1{\textcolor[rgb]{0.44,0.44,0.44}{##1}}}
\@namedef{PY@tok@gt}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\@namedef{PY@tok@err}{\def\PY@bc##1{{\setlength{\fboxsep}{\string -\fboxrule}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}}
\@namedef{PY@tok@kc}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kd}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kn}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@kr}{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@bp}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\@namedef{PY@tok@fm}{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\@namedef{PY@tok@vc}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vg}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vi}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@vm}{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\@namedef{PY@tok@sa}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sb}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sc}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@dl}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s2}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@sh}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@s1}{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\@namedef{PY@tok@mb}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mf}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mh}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mi}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@il}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@mo}{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\@namedef{PY@tok@ch}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cm}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cpf}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@c1}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}
\@namedef{PY@tok@cs}{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.24,0.48,0.48}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % For linebreaks inside Verbatim environment from package fancyvrb.
    \makeatletter
        \newbox\Wrappedcontinuationbox
        \newbox\Wrappedvisiblespacebox
        \newcommand*\Wrappedvisiblespace {\textcolor{red}{\textvisiblespace}}
        \newcommand*\Wrappedcontinuationsymbol {\textcolor{red}{\llap{\tiny$\m@th\hookrightarrow$}}}
        \newcommand*\Wrappedcontinuationindent {3ex }
        \newcommand*\Wrappedafterbreak {\kern\Wrappedcontinuationindent\copy\Wrappedcontinuationbox}
        % Take advantage of the already applied Pygments mark-up to insert
        % potential linebreaks for TeX processing.
        %        {, <, #, %, $, ' and ": go to next line.
        %        _, }, ^, &, >, - and ~: stay at end of broken line.
        % Use of \textquotesingle for straight quote.
        \newcommand*\Wrappedbreaksatspecials {%
            \def\PYGZus{\discretionary{\char`\_}{\Wrappedafterbreak}{\char`\_}}%
            \def\PYGZob{\discretionary{}{\Wrappedafterbreak\char`\{}{\char`\{}}%
            \def\PYGZcb{\discretionary{\char`\}}{\Wrappedafterbreak}{\char`\}}}%
            \def\PYGZca{\discretionary{\char`\^}{\Wrappedafterbreak}{\char`\^}}%
            \def\PYGZam{\discretionary{\char`\&}{\Wrappedafterbreak}{\char`\&}}%
            \def\PYGZlt{\discretionary{}{\Wrappedafterbreak\char`\<}{\char`\<}}%
            \def\PYGZgt{\discretionary{\char`\>}{\Wrappedafterbreak}{\char`\>}}%
            \def\PYGZsh{\discretionary{}{\Wrappedafterbreak\char`\#}{\char`\#}}%
            \def\PYGZpc{\discretionary{}{\Wrappedafterbreak\char`\%}{\char`\%}}%
            \def\PYGZdl{\discretionary{}{\Wrappedafterbreak\char`\$}{\char`\$}}%
            \def\PYGZhy{\discretionary{\char`\-}{\Wrappedafterbreak}{\char`\-}}%
            \def\PYGZsq{\discretionary{}{\Wrappedafterbreak\textquotesingle}{\textquotesingle}}%
            \def\PYGZdq{\discretionary{}{\Wrappedafterbreak\char`\"}{\char`\"}}%
            \def\PYGZti{\discretionary{\char`\~}{\Wrappedafterbreak}{\char`\~}}%
        }
        % Some characters . , ; ? ! / are not pygmentized.
        % This macro makes them "active" and they will insert potential linebreaks
        \newcommand*\Wrappedbreaksatpunct {%
            \lccode`\~`\.\lowercase{\def~}{\discretionary{\hbox{\char`\.}}{\Wrappedafterbreak}{\hbox{\char`\.}}}%
            \lccode`\~`\,\lowercase{\def~}{\discretionary{\hbox{\char`\,}}{\Wrappedafterbreak}{\hbox{\char`\,}}}%
            \lccode`\~`\;\lowercase{\def~}{\discretionary{\hbox{\char`\;}}{\Wrappedafterbreak}{\hbox{\char`\;}}}%
            \lccode`\~`\:\lowercase{\def~}{\discretionary{\hbox{\char`\:}}{\Wrappedafterbreak}{\hbox{\char`\:}}}%
            \lccode`\~`\?\lowercase{\def~}{\discretionary{\hbox{\char`\?}}{\Wrappedafterbreak}{\hbox{\char`\?}}}%
            \lccode`\~`\!\lowercase{\def~}{\discretionary{\hbox{\char`\!}}{\Wrappedafterbreak}{\hbox{\char`\!}}}%
            \lccode`\~`\/\lowercase{\def~}{\discretionary{\hbox{\char`\/}}{\Wrappedafterbreak}{\hbox{\char`\/}}}%
            \catcode`\.\active
            \catcode`\,\active
            \catcode`\;\active
            \catcode`\:\active
            \catcode`\?\active
            \catcode`\!\active
            \catcode`\/\active
            \lccode`\~`\~
        }
    \makeatother

    \let\OriginalVerbatim=\Verbatim
    \makeatletter
    \renewcommand{\Verbatim}[1][1]{%
        %\parskip\z@skip
        \sbox\Wrappedcontinuationbox {\Wrappedcontinuationsymbol}%
        \sbox\Wrappedvisiblespacebox {\FV@SetupFont\Wrappedvisiblespace}%
        \def\FancyVerbFormatLine ##1{\hsize\linewidth
            \vtop{\raggedright\hyphenpenalty\z@\exhyphenpenalty\z@
                \doublehyphendemerits\z@\finalhyphendemerits\z@
                \strut ##1\strut}%
        }%
        % If the linebreak is at a space, the latter will be displayed as visible
        % space at end of first line, and a continuation symbol starts next line.
        % Stretch/shrink are however usually zero for typewriter font.
        \def\FV@Space {%
            \nobreak\hskip\z@ plus\fontdimen3\font minus\fontdimen4\font
            \discretionary{\copy\Wrappedvisiblespacebox}{\Wrappedafterbreak}
            {\kern\fontdimen2\font}%
        }%

        % Allow breaks at special characters using \PYG... macros.
        \Wrappedbreaksatspecials
        % Breaks at punctuation characters . , ; ? ! and / need catcode=\active
        \OriginalVerbatim[#1,codes*=\Wrappedbreaksatpunct]%
    }
    \makeatother

    % Exact colors from NB
    \definecolor{incolor}{HTML}{303F9F}
    \definecolor{outcolor}{HTML}{D84315}
    \definecolor{cellborder}{HTML}{CFCFCF}
    \definecolor{cellbackground}{HTML}{F7F7F7}

    % prompt
    \makeatletter
    \newcommand{\boxspacing}{\kern\kvtcb@left@rule\kern\kvtcb@boxsep}
    \makeatother
    \newcommand{\prompt}[4]{
        {\ttfamily\llap{{\color{#2}[#3]:\hspace{3pt}#4}}\vspace{-\baselineskip}}
    }
    

    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

\begin{document}
    
    \maketitle
    
    

    
    \hypertarget{weighing-options-in-the-public-sector}{%
\section{Weighing Options In The Public
Sector}\label{weighing-options-in-the-public-sector}}

\hypertarget{an-exploration-of-oregon-government-jobs}{%
\subsection{An Exploration of Oregon Government
Jobs}\label{an-exploration-of-oregon-government-jobs}}

If I decided to get a ``real'' job, and stop being an IT contractor,
working in the public sector is an option. I know they get decent
benefits, but there are a lot of factors to weigh. This is an
exploration of government jobs and salaries pulled from Oregon's
government transparancy website.

\hypertarget{some-assumptions-and-caveats}{%
\subsection{Some Assumptions and
Caveats}\label{some-assumptions-and-caveats}}

\begin{itemize}
\item
  This data is real life and economic based (which is to say, messy as
  hell):

  \begin{itemize}
  \tightlist
  \item
    We will be using an alpha of 0.05, (this ain't physics).
  \item
    When we use confidence intervals, we'll keep it to 90\%, (when was
    the last time you were more than 90\% sure of something irl?)
  \end{itemize}
\item
  I will \emph{try} not to just assume a normal distribution without
  explicitly saying so otherwise (I'll still make this assumption a
  lot). Again this stuff is messy, very little of the underlying
  distributions are perfectly or even roughly normal distributions:
\item
  There is too much data to be working with by hand (27MB):

  \begin{itemize}
  \tightlist
  \item
    I will be making heavy use of R to do the work for me for this
    presentation.
  \item
    I will mostly only display relevent results.
  \end{itemize}
\item
  I'm on a schedule:

  \begin{itemize}
  \tightlist
  \item
    I don't \emph{really} know R's syntax, grammer, builtin functions or
    syntatical sugar. I'll put in some code comments to explain what I'm
    doing but this code will be hacky. \textbf{Don't judge me}.
  \item
    Where I can (\emph{and if it's not too annoying}), I'll try and show
    some of the calculations in longer form.
  \end{itemize}
\item
  This is for class. I'm trying to show I learned anything, sometimes
  the data makes that hard to do:

  \begin{itemize}
  \tightlist
  \item
    Where appropriate (or not too egregious) I \textbf{will} randomly
    sample from populations and just assume it's normal (\emph{or if
    it's just convienient---sue me}).
  \item
    I make no promises more that ``mostly accurate''. \textbf{Don't}
    make life decisions based on what I've done here.
  \item
    If you want accuracy go read five-thirty-eight or something.
  \end{itemize}
\end{itemize}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{1}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Import the data and lowercase the column names}
\PY{n+nf}{options}\PY{p}{(}\PY{n}{warn}\PY{o}{=}\PY{l+m}{\PYZhy{}1}\PY{p}{)}
\PY{n+nf}{options}\PY{p}{(}\PY{n}{digits}\PY{o}{=}\PY{l+m}{5}\PY{p}{)}
\PY{n+nf}{set.seed}\PY{p}{(}\PY{l+m}{99}\PY{p}{)}
\PY{n}{SAL} \PY{o}{\PYZlt{}\PYZhy{}}\PY{n+nf}{read.csv}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Salaries\PYZus{}of\PYZus{}State\PYZus{}Agencies\PYZus{}\PYZhy{}\PYZus{}Multi\PYZhy{}Year\PYZus{}Report.csv\PYZdq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{n+nb+bp}{T}\PY{p}{)}
\PY{n+nf}{names}\PY{p}{(}\PY{n}{SAL}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{tolower}\PY{p}{(}\PY{n+nf}{names}\PY{p}{(}\PY{n}{SAL}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{2}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{SAL}\PY{p}{[}\PY{l+m}{12}\PY{o}{:}\PY{l+m}{20}\PY{p}{,}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    A data.frame: 9 × 7
\begin{tabular}{r|lllllll}
  & fiscal.year & agency & classification & salary.annual & full.part.time & service.type & agency.1\\
  & <int> & <chr> & <chr> & <int> & <chr> & <chr> & <int>\\
\hline
	12 & 2015 & CORRECTIONS, DEPT OF    & DENTIST          & 176352 & JOB SHARE & REPRESENTED       & 29100\\
	13 & 2015 & CORRECTIONS, DEPT OF    & DENTIST          & 176352 & PART TIME & REPRESENTED       & 29100\\
	14 & 2015 & CORRECTIONS, DEPT OF    & WELDER 2         &  70494 & FULL TIME & REPRESENTED       & 29100\\
	15 & 2015 & CORRECTIONS, DEPT OF    & WELDER 2         &  70806 & FULL TIME & REPRESENTED       & 29100\\
	16 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100\\
	17 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100\\
	18 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100\\
	19 & 2015 & YOUTH AUTHORITY, OREGON & FISCAL ANALYST 2 &  69624 & FULL TIME & REPRESENTED       & 41500\\
	20 & 2015 & YOUTH AUTHORITY, OREGON & FISCAL ANALYST 3 &  62772 & FULL TIME & EXECUTIVE SERVICE & 41500\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{3}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{attach}\PY{p}{(}\PY{n}{SAL}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{4}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{library}\PY{p}{(}\PY{n}{stringr}\PY{p}{)} \PY{c+c1}{\PYZsh{} a regex and string manipulation library}

\PY{c+c1}{\PYZsh{} Clean some relevent data and put it back in}
\PY{n}{classification} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{str\PYZus{}replace}\PY{p}{(}\PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{classification}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{TECHNICIAN\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{TECH\PYZdq{}}\PY{p}{)}
\PY{n}{classification} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{str\PYZus{}replace}\PY{p}{(}\PY{n}{classification}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{SPEC\PYZdl{}\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{SPECIALIST\PYZdq{}}\PY{p}{)}
\PY{n}{classification}  \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{str\PYZus{}replace}\PY{p}{(}\PY{n}{classification}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{SUPV\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{SUPERVISOR\PYZdq{}}\PY{p}{)}
\PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{classification} \PY{o}{=} \PY{n}{classification}

\PY{c+c1}{\PYZsh{} add another column to allow me to group the same jobs together}
\PY{n}{GEN\PYZus{}CLASS}  \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{str\PYZus{}extract}\PY{p}{(}\PY{n}{classification}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{(.+)[\PYZca{}\PYZbs{}\PYZbs{}s|\PYZbs{}\PYZbs{}d|I]\PYZdq{}}\PY{p}{)}
\PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{GEN\PYZus{}CLASS}
\PY{n}{SAL}\PY{p}{[}\PY{l+m}{12}\PY{o}{:}\PY{l+m}{20}\PY{p}{,}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    A data.frame: 9 × 8
\begin{tabular}{r|llllllll}
  & fiscal.year & agency & classification & salary.annual & full.part.time & service.type & agency.1 & gen\_class\\
  & <int> & <chr> & <chr> & <int> & <chr> & <chr> & <int> & <chr>\\
\hline
	12 & 2015 & CORRECTIONS, DEPT OF    & DENTIST          & 176352 & JOB SHARE & REPRESENTED       & 29100 & DENTIST       \\
	13 & 2015 & CORRECTIONS, DEPT OF    & DENTIST          & 176352 & PART TIME & REPRESENTED       & 29100 & DENTIST       \\
	14 & 2015 & CORRECTIONS, DEPT OF    & WELDER 2         &  70494 & FULL TIME & REPRESENTED       & 29100 & WELDER        \\
	15 & 2015 & CORRECTIONS, DEPT OF    & WELDER 2         &  70806 & FULL TIME & REPRESENTED       & 29100 & WELDER        \\
	16 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100 & CUSTODIAN     \\
	17 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100 & CUSTODIAN     \\
	18 & 2015 & EDUCATION, DEPT OF      & CUSTODIAN        &  31632 & PART TIME & REPRESENTED       & 58100 & CUSTODIAN     \\
	19 & 2015 & YOUTH AUTHORITY, OREGON & FISCAL ANALYST 2 &  69624 & FULL TIME & REPRESENTED       & 41500 & FISCAL ANALYST\\
	20 & 2015 & YOUTH AUTHORITY, OREGON & FISCAL ANALYST 3 &  62772 & FULL TIME & EXECUTIVE SERVICE & 41500 & FISCAL ANALYST\\
\end{tabular}


    
    \hypertarget{getting-my-feet-wet-creeping-on-people-i-met-once}{%
\section{Getting My Feet Wet: Creeping On People I Met
Once}\label{getting-my-feet-wet-creeping-on-people-i-met-once}}

\hypertarget{which-dept.-did-that-woman-i-met-work-at}{%
\subsection{Which Dept. Did That Woman I Met Work
At?}\label{which-dept.-did-that-woman-i-met-work-at}}

I met a woman at a python conference in early 2020. She said she worked
or had worked for the government as an analyst---I can't remember which.
We talked about what we did for a while, and I asked how well her job
payed; she said that she made ``around 65 grand'' per year.

To do this analysis, we're gonna make some assumptions and pretend some
stuff.

\begin{itemize}
\tightlist
\item
  analyst pay in each dept is normally distributed (it probably isn't
  exactly, but a look at some graphs look roughly normal, good enough
  for me)
\item
  Pretend I \textbf{don't} have access to the full population dataset
\end{itemize}

We're gonna pretend that I went to each department and asked 10
analyists what they made. Also I'll pretend that I did this over the
period from 2015-2020 (all samples randomly and indepently chosen).
We'll use that to estimate the distribution for each department.

    \hypertarget{step-1-filter-the-data}{%
\subsection{Step 1: Filter the data}\label{step-1-filter-the-data}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{5}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Filter on what we\PYZsq{}re looking for}
\PY{n}{analysts} \PY{o}{=} \PY{n}{SAL}\PY{p}{[}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{ANALYST\PYZdq{}}\PY{p}{)}\PY{o}{\PYZam{}}\PY{n}{fiscal.year}\PY{o}{\PYZlt{}=}\PY{l+m}{2020} \PY{o}{\PYZam{}} \PY{n}{full.part.time}\PY{o}{==}\PY{l+s}{\PYZdq{}}\PY{l+s}{FULL TIME\PYZdq{}}\PY{p}{,}\PY{p}{]}

\PY{c+c1}{\PYZsh{} We\PYZsq{}ll only use departments that have more than 10 analyists, can\PYZsq{}t get 10 samples otherwise.}

\PY{n}{counts} \PY{o}{=} \PY{n+nf}{as.data.frame}\PY{p}{(}\PY{n+nf}{table}\PY{p}{(}\PY{n}{analysts}\PY{o}{\PYZdl{}}\PY{n}{agency}\PY{p}{)}\PY{p}{)}
\PY{n}{dept\PYZus{}names} \PY{o}{=} \PY{n}{counts}\PY{p}{[}\PY{n}{counts}\PY{p}{[}\PY{l+m}{2}\PY{p}{]}\PY{o}{\PYZgt{}=}\PY{l+m}{10}\PY{p}{,} \PY{l+m}{1}\PY{p}{]}


\PY{n}{analysts} \PY{o}{=} \PY{n}{analysts}\PY{p}{[}\PY{n}{analysts}\PY{o}{\PYZdl{}}\PY{n}{agency} \PY{o}{\PYZpc{}in\PYZpc{}} \PY{n}{dept\PYZus{}names}\PY{p}{,} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{agency\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{salary.annual\PYZdq{}}\PY{p}{)} \PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{6}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{nrow}\PY{p}{(}\PY{n+nf}{as.data.frame}\PY{p}{(}\PY{n+nf}{table}\PY{p}{(}\PY{n}{analysts}\PY{o}{\PYZdl{}}\PY{n}{agency}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    56

    
    \hypertarget{step-2-see-if-theres-even-a-difference-between-the-average-salaries-in-each-department}{%
\subsection{Step 2: See If There's Even A Difference Between The Average
Salaries In Each
Department}\label{step-2-see-if-theres-even-a-difference-between-the-average-salaries-in-each-department}}

To do this, we're going to conduct an anova test. For this test we are
going to assume: 1. Each departments salary distribution is normal (same
as we said above) 2. Each departments standard deviation is the same
(Not something we're really confident about)

The groups for the anova test are going to be the departments. Here are
our hypotheses:

H0: each department pays their analysts the same on average.

HA: each department does \textbf{not} pay their analysts the same on
average.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{7}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} function to build a df of 10 samples for each department (long form), no pivot}

\PY{n}{samp10} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{dept\PYZus{}names}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{new} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{dept}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{,} \PY{n}{sample}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{)}
    \PY{n+nf}{for }\PY{p}{(}\PY{n}{name} \PY{n}{in} \PY{n}{dept\PYZus{}names}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{salaries} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{data}\PY{o}{\PYZdl{}}\PY{n}{agency} \PY{o}{==} \PY{n}{name}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}
        \PY{n+nf}{for}\PY{p}{(}\PY{n}{x} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{l+m}{10}\PY{p}{)}\PY{p}{\PYZob{}}
            \PY{n}{r} \PY{o}{=} \PY{n+nf}{floor}\PY{p}{(}\PY{n+nf}{runif}\PY{p}{(}\PY{l+m}{1}\PY{p}{,} \PY{n}{min}\PY{o}{=}\PY{l+m}{1}\PY{p}{,} \PY{n}{max}\PY{o}{=}\PY{n+nf}{length}\PY{p}{(}\PY{n}{salaries}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            \PY{n}{row} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{name}\PY{p}{,} \PY{n}{salaries}\PY{p}{[}\PY{n}{r}\PY{p}{]}\PY{p}{)}
            \PY{n}{salaries} \PY{o}{=} \PY{n}{salaries}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{n}{r}\PY{p}{]}
            \PY{n}{new}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{new}\PY{p}{)}\PY{l+m}{+1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n}{row}
        \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
    \PY{n}{new}
\PY{p}{\PYZcb{}}

\PY{n}{samples} \PY{o}{=} \PY{n+nf}{samp10}\PY{p}{(}\PY{n}{analysts}\PY{p}{,} \PY{n}{dept\PYZus{}names}\PY{p}{)}

\PY{n}{model} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{sample}\PY{o}{\PYZti{}}\PY{n}{dept}\PY{p}{,} \PY{n}{samples}\PY{p}{)}

\PY{n+nf}{anova}\PY{p}{(}\PY{n}{model}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    A anova: 2 × 5
\begin{tabular}{r|lllll}
  & Df & Sum Sq & Mean Sq & F value & Pr(>F)\\
  & <int> & <dbl> & <dbl> & <dbl> & <dbl>\\
\hline
	dept &  55 & 7.9329e+10 & 1442343224 & 6.1266 & 2.7597e-30\\
	Residuals & 504 & 1.1865e+11 &  235422622 &     NA &         NA\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{8}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Let\PYZsq{}s see if this answer makes any sense}
\PY{c+c1}{\PYZsh{} We\PYZsq{}ll make boxplots for the samples of each department and see if we can get anything out of it}

\PY{n+nf}{boxplot}\PY{p}{(}\PY{n}{samples}\PY{o}{\PYZdl{}}\PY{n}{sample}\PY{o}{\PYZti{}}\PY{n}{samples}\PY{o}{\PYZdl{}}\PY{n}{dept}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkseagreen\PYZdq{}}\PY{p}{,} \PY{n}{outcol}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{red\PYZdq{}}\PY{p}{,} \PY{n}{ylab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Pay\PYZdq{}}\PY{p}{,} \PY{n}{xlab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Departments\PYZdq{}}\PY{p}{,} \PY{n}{xaxt}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{n\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_13_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    It's pretty clear looking at the graph that there is quite a lot of
variance in the mean pay among the departments, With 2 particular
outliers in the middle.

\hypertarget{step-3-in-comes-the-bayes}{%
\subsection{Step 3: In Comes The
Bayes}\label{step-3-in-comes-the-bayes}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{9}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} make a table of the estimated normal distribution values (N\PYZob{}Ybar\PYZus{}i, S\PYZus{}i\PYZca{}2\PYZcb{}) for each department given their samples}

\PY{n}{dfs} \PY{o}{=} \PY{n+nf}{split}\PY{p}{(}\PY{n}{samples}\PY{p}{,} \PY{n}{samples}\PY{o}{\PYZdl{}}\PY{n}{dept}\PY{p}{)}
\PY{n}{params} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{agency}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{avg}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{sd}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{for }\PY{p}{(}\PY{n}{df} \PY{n}{in} \PY{n}{dfs}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{params}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{l+m}{+1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{dept}\PY{p}{[}\PY{l+m}{1}\PY{p}{]}\PY{p}{,} \PY{n+nf}{mean}\PY{p}{(}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{sample}\PY{p}{)}\PY{p}{,} \PY{n+nf}{sd}\PY{p}{(}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{sample}\PY{p}{)}\PY{p}{)}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} decide on an acceptible range we\PYZsq{}ll say +\PYZhy{} 2 grand from what she said, why not}
\PY{c+c1}{\PYZsh{} we\PYZsq{}ll add on a new row that contains the probabilty of getting a salary between 63000 and 67000 for each department}

\PY{n}{probs} \PY{o}{=} \PY{n+nf}{numeric}\PY{p}{(}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{p}{)}

\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in}  \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{m} \PY{o}{=} \PY{n}{params}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{avg\PYZdq{}}\PY{p}{]}
    \PY{n}{sd} \PY{o}{=} \PY{n}{params}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{sd\PYZdq{}}\PY{p}{]}
    \PY{n}{probs}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n+nf}{pnorm}\PY{p}{(}\PY{l+m}{67000}\PY{p}{,} \PY{n}{m}\PY{p}{,} \PY{n}{sd}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n+nf}{pnorm}\PY{p}{(}\PY{l+m}{63000}\PY{p}{,} \PY{n}{m}\PY{p}{,} \PY{n}{sd}\PY{p}{)}
\PY{p}{\PYZcb{}}
\PY{c+c1}{\PYZsh{} add a column representing the probability of getting that salary given she works in that department}
\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}sal\PYZus{}g\PYZus{}dpt} \PY{o}{=} \PY{n}{probs}
\PY{n+nf}{head}\PY{p}{(}\PY{n}{params}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    A data.frame: 6 × 4
\begin{tabular}{r|llll}
  & agency & avg & sd & p\_sal\_g\_dpt\\
  & <chr> & <dbl> & <dbl> & <dbl>\\
\hline
	1 & ADMINISTRATIVE SRVCS, DEPT OF & 77948 & 16785 & 0.070535\\
	2 & AGRICULTURE, DEPT OF          & 71245 & 14785 & 0.098472\\
	3 & AVIATION, DEPARTMENT OF       & 64823 & 12195 & 0.130255\\
	4 & BLIND, COMMISSION FOR THE     & 70572 & 13809 & 0.106213\\
	5 & CHIEF EDUCATION OFFICE        & 69052 & 11634 & 0.128540\\
	6 & COMM COLL/WRKFRCE DEV OFFICE  & 74422 & 12343 & 0.096430\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{10}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Now we\PYZsq{}ll calculate the conditional probability (bayes) of Pr\PYZob{}agency|pay\PYZcb{} for each department}

\PY{c+c1}{\PYZsh{} to calculate the raw probabilty of being from each department, we need to calculate the proportion}
\PY{c+c1}{\PYZsh{} of analysts in each department}

\PY{n}{total\PYZus{}analysts} \PY{o}{=} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{analysts}\PY{p}{)}
\PY{n}{p\PYZus{}dpt} \PY{o}{=} \PY{n+nf}{numeric}\PY{p}{(}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{params}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{dpt} \PY{o}{=} \PY{n}{params}\PY{p}{[}\PY{n}{i}\PY{p}{,} \PY{l+m}{1}\PY{p}{]}
    \PY{n}{a\PYZus{}in\PYZus{}dpt} \PY{o}{=} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{analysts}\PY{p}{[}\PY{n}{analysts}\PY{o}{\PYZdl{}}\PY{n}{agency}\PY{o}{==}\PY{n}{dpt}\PY{p}{,}\PY{p}{]}\PY{p}{)}
    \PY{n}{p\PYZus{}dpt}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{a\PYZus{}in\PYZus{}dpt} \PY{o}{/} \PY{n}{total\PYZus{}analysts}
\PY{p}{\PYZcb{}}
\PY{c+c1}{\PYZsh{} a row representing the probabilty of being from each department}
\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt} \PY{o}{=} \PY{n}{p\PYZus{}dpt}

\PY{c+c1}{\PYZsh{} now we calculate the overall probability of a random person getting that salary}
\PY{n}{p\PYZus{}sal} \PY{o}{=} \PY{n+nf}{sum}\PY{p}{(}\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt} \PY{o}{*} \PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}sal\PYZus{}g\PYZus{}dpt}\PY{p}{)}

\PY{c+c1}{\PYZsh{} And do the bayes calculation}
\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal} \PY{o}{=} \PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}sal\PYZus{}g\PYZus{}dpt} \PY{o}{*} \PY{n}{p\PYZus{}dpt} \PY{o}{/} \PY{n}{p\PYZus{}sal}

\PY{c+c1}{\PYZsh{} as a sanity check, we\PYZsq{}ll see if all the conditional probabilities sum to 1 (she has to be from one of them)}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{All conditional probs sum to 1: \PYZdq{}}\PY{p}{,}\PY{n+nf}{sum}\PY{p}{(}\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal}\PY{p}{)} \PY{o}{==} \PY{l+m}{1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} and lets take a look!}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{params}\PY{p}{[}\PY{n+nf}{order}\PY{p}{(}\PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal}\PY{p}{)}\PY{p}{,}\PY{n+nf}{c}\PY{p}{(}\PY{l+m}{1}\PY{p}{,} \PY{l+m}{6}\PY{p}{)}\PY{p}{]}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
All conditional probs sum to 1:  TRUE
    \end{Verbatim}

    A data.frame: 6 × 2
\begin{tabular}{r|ll}
  & agency & p\_dpt\_g\_sal\\
  & <chr> & <dbl>\\
\hline
	1 & ADMINISTRATIVE SRVCS, DEPT OF & 0.035612\\
	8 & CONSUMER AND BUS SRVCS, DEPT  & 0.036430\\
	46 & PUBLIC EMPS RETIREMENT SYSTEM & 0.061756\\
	52 & TRANSPORTATION, DEPT OF       & 0.103228\\
	39 & OREGON HEALTH AUTHORITY       & 0.182191\\
	21 & HUMAN SERVICES, DEPARTMENT OF & 0.218585\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{11}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Out of curiosity, lets take a quick look at how well the size of the department and the probabilty of}
\PY{c+c1}{\PYZsh{} Getting some department given that salary are corrolated}
\PY{c+c1}{\PYZsh{} in otherwords, could we just have looked at the analysts proportions and gotten a reasonable result?}

\PY{c+c1}{\PYZsh{} I\PYZsq{}ll calculate r by \PYZdq{}hand\PYZdq{} and use R to double check my work}

\PY{n}{x} \PY{o}{=} \PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt}
\PY{n}{y} \PY{o}{=} \PY{n}{params}\PY{o}{\PYZdl{}}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal}
\PY{n}{xhat} \PY{o}{=} \PY{n+nf}{mean}\PY{p}{(}\PY{n}{x}\PY{p}{)}
\PY{n}{yhat} \PY{o}{=} \PY{n+nf}{mean}\PY{p}{(}\PY{n}{y}\PY{p}{)}
\PY{n}{sx} \PY{o}{=} \PY{n+nf}{sd}\PY{p}{(}\PY{n}{x}\PY{p}{)}
\PY{n}{sy} \PY{o}{=} \PY{n+nf}{sd}\PY{p}{(}\PY{n}{y}\PY{p}{)}

\PY{n}{err\PYZus{}x} \PY{o}{=} \PY{p}{(}\PY{n}{x}\PY{o}{\PYZhy{}}\PY{n}{xhat}\PY{p}{)}\PY{o}{/}\PY{n}{sx}
\PY{n}{err\PYZus{}y} \PY{o}{=} \PY{p}{(}\PY{n}{y}\PY{o}{\PYZhy{}}\PY{n}{yhat}\PY{p}{)}\PY{o}{/}\PY{n}{sy}

\PY{n}{r} \PY{o}{=} \PY{n+nf}{sum}\PY{p}{(}\PY{n}{err\PYZus{}x}\PY{o}{*}\PY{n}{err\PYZus{}y}\PY{p}{)} \PY{o}{/} \PY{p}{(}\PY{n+nf}{length}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{l+m}{\PYZhy{}1}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Check my work}
\PY{n+nf}{if}\PY{p}{(}\PY{n}{r} \PY{o}{\PYZhy{}} \PY{n+nf}{cor}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)} \PY{o}{\PYZlt{}=} \PY{l+m}{3e\PYZhy{}16}\PY{p}{)}\PY{p}{\PYZob{}}  \PY{c+c1}{\PYZsh{} difference is within floating precision error}
    \PY{n+nf}{print}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Hand Calculations and R agree!\PYZdq{}}\PY{p}{)}
\PY{p}{\PYZcb{}}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{The Corrolation coeficient \PYZbs{}\PYZdq{}r\PYZbs{}\PYZdq{} for these two variables is \PYZdq{}}\PY{p}{,}\PY{n}{r}\PY{p}{)}
\PY{c+c1}{\PYZsh{} May as well graph it too. Everyone likes graphs.}
\PY{n}{fit} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal} \PY{o}{\PYZti{}} \PY{n}{p\PYZus{}dpt}\PY{p}{,} \PY{n}{params}\PY{p}{)}
\PY{n+nf}{plot}\PY{p}{(}\PY{n}{p\PYZus{}dpt\PYZus{}g\PYZus{}sal} \PY{o}{\PYZti{}} \PY{n}{p\PYZus{}dpt}\PY{p}{,} \PY{n}{params}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkblue\PYZdq{}}\PY{p}{,} \PY{n}{xlab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Proportion of Employed Analyists\PYZdq{}}\PY{p}{,} \PY{n}{ylab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Probability of Dept. Given Salary\PYZdq{}}\PY{p}{)}
\PY{n+nf}{abline}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkviolet\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
[1] "Hand Calculations and R agree!"
The Corrolation coeficient "r" for these two variables is  0.9829
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_17_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Yep, an almost perfect positive corrolation. We could have saved a ton
of work if we had just looked at the porportions of total analysts. A
little depressing.

    \hypertarget{now-its-all-about-me}{%
\section{Now It's All About ME}\label{now-its-all-about-me}}

Now that I've become a little more familiar with the data, it's time to
do some statistics that help answer my more pressing concerns. Is it
worth it for me to try to get into the public sector?

    \hypertarget{will-the-public-sector-even-be-hiring}{%
\section{Will The Public Sector Even Be
Hiring?}\label{will-the-public-sector-even-be-hiring}}

\hypertarget{overall-year-over-year-job-growth}{%
\subsubsection{Overall Year-Over-Year Job
Growth}\label{overall-year-over-year-job-growth}}

First things first, will there even be enough growth in the govenment
for me to get hired?

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{12}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} group all employes by year and make a table and a linear regression}
\PY{n}{years} \PY{o}{=} \PY{n+nf}{split}\PY{p}{(}\PY{n}{SAL}\PY{p}{,} \PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{fiscal.year}\PY{p}{)}


\PY{n}{employees} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{dfs}\PY{p}{)}\PY{p}{\PYZob{}}  \PY{c+c1}{\PYZsh{} Extracts the number of employees from a set of dataframes}
    \PY{n}{counts} \PY{o}{=} \PY{n+nf}{numeric}\PY{p}{(}\PY{n+nf}{length}\PY{p}{(}\PY{n}{dfs}\PY{p}{)}\PY{p}{)}
    \PY{n+nf}{for }\PY{p}{(}\PY{n}{i} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{dfs}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{f} \PY{o}{=} \PY{n}{dfs}\PY{p}{[[}\PY{n}{i}\PY{p}{]]}
        \PY{n}{counts}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{f}\PY{p}{)}
    \PY{p}{\PYZcb{}}
    \PY{n}{counts}
\PY{p}{\PYZcb{}}


\PY{n}{emp} \PY{o}{=} \PY{n+nf}{employees}\PY{p}{(}\PY{n}{years}\PY{p}{)}
\PY{n}{emp} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{Year} \PY{o}{=} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{emp}\PY{p}{)}\PY{l+m}{+2014}\PY{p}{,} \PY{n}{Workers}\PY{o}{=}\PY{n}{emp}\PY{p}{)}

\PY{n}{lrg} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{Workers}\PY{o}{\PYZti{}}\PY{n}{Year}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{emp}\PY{p}{)}
\PY{n}{summ} \PY{o}{=} \PY{n+nf}{summary}\PY{p}{(}\PY{n}{lrg}\PY{p}{)}
\PY{c+c1}{\PYZsh{} Growth estimate}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Job Growth Estimate: \PYZdq{}}\PY{p}{,} \PY{n}{summ}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m}{2}\PY{p}{,} \PY{l+m}{1}\PY{p}{]}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calculate confidence interval:}
\PY{c+c1}{\PYZsh{}    Pulling out Values from linear model summary, because I\PYZsq{}m lazy}

\PY{n}{sderr} \PY{o}{=} \PY{n}{summ}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m}{2}\PY{p}{,} \PY{l+m}{2}\PY{p}{]}
\PY{n}{b1} \PY{o}{=} \PY{n}{summ}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m}{2}\PY{p}{,} \PY{l+m}{1}\PY{p}{]}
\PY{n}{tda} \PY{o}{=} \PY{n+nf}{qt}\PY{p}{(}\PY{l+m}{0.95}\PY{p}{,} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{emp}\PY{p}{)}\PY{l+m}{\PYZhy{}2}\PY{p}{)}
\PY{n}{tda}
\PY{c+c1}{\PYZsh{}tval (found at summ\PYZdl{}coefficients[2,3] (I\PYZsq{}ll do it below, for now))}

\PY{c+c1}{\PYZsh{}    calc interval}


\PY{n}{ci} \PY{o}{=} \PY{n+nf}{c}\PY{p}{(}\PY{n}{b1} \PY{o}{\PYZhy{}} \PY{n}{tda} \PY{o}{*} \PY{n}{sderr}\PY{p}{,} \PY{n}{b1} \PY{o}{+} \PY{n}{tda} \PY{o}{*} \PY{n}{sderr}\PY{p}{)} \PY{c+c1}{\PYZsh{} more easily done with confint(lrg, level=\PYZpc{})[2,]}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n90\PYZpc{} confidence interval for job growth: [\PYZdq{}}\PY{p}{,} \PY{n}{ci}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{]\PYZbs{}n\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} How many new jobs can I expect to be added next year?}
\PY{n}{expected2023} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{lrg}\PY{p}{,} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{Year}\PY{o}{=}\PY{l+m}{2023}\PY{p}{)}\PY{p}{)}
\PY{n}{jobs2022} \PY{o}{=} \PY{n}{emp}\PY{p}{[}\PY{l+m}{8}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}nExpected new jobs in 2023: \PYZdq{}}\PY{p}{,} \PY{n+nf}{as.integer}\PY{p}{(}\PY{n}{expected2023} \PY{o}{\PYZhy{}} \PY{n}{jobs2022}\PY{p}{)}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZdq{}}\PY{p}{)}


\PY{c+c1}{\PYZsh{} Plot with trend}
\PY{c+c1}{\PYZsh{}emp}
\PY{n+nf}{plot}\PY{p}{(}\PY{n}{emp}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkblue\PYZdq{}}\PY{p}{)}
\PY{n+nf}{abline}\PY{p}{(}\PY{n}{lrg}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkviolet\PYZdq{}}\PY{p}{)}

\PY{c+c1}{\PYZsh{} Calc P val (found at summ\PYZdl{}coefficients[2,4], if you don\PYZsq{}t feel like doing it yourself)}
\PY{n}{tstat} \PY{o}{=} \PY{p}{(}\PY{n}{b1}\PY{l+m}{\PYZhy{}0}\PY{p}{)}\PY{o}{/}\PY{n}{sderr}
\PY{n}{tstat}
\PY{n}{pval} \PY{o}{=} \PY{l+m}{1}\PY{o}{\PYZhy{}}\PY{n+nf}{pt}\PY{p}{(}\PY{n}{tstat}\PY{p}{,} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{emp}\PY{p}{)}\PY{l+m}{\PYZhy{}2}\PY{p}{)}
\PY{n}{pval}
\PY{n+nf}{cat}\PY{p}{(}\PY{n+nf}{paste}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}n\PYZbs{}nP\PYZhy{}value: \PYZdq{}}\PY{p}{,} \PY{n}{pval}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Job Growth Estimate:  1013.8

    \end{Verbatim}

    1.9431802805153

    
    \begin{Verbatim}[commandchars=\\\{\}]

90\% confidence interval for job growth: [ 295.75 1731.8 ]


Expected new jobs in 2023:  -2351
    \end{Verbatim}

    2.74354019106661

    
    0.0167889028962795

    
    \begin{Verbatim}[commandchars=\\\{\}]


P-value:  0.0167889028962795
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_21_6.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{itemize}
\item
  It looks like we may expect OR to \emph{lose} about 2300 jobs next
  year. This is likely because 2022 seems to be an outlier in growth.
  Wheter this will be the case that 2023 will be a regression to the
  mean, or that 2023 will be the start of a new boom in jobs (something
  that will make us increase our growth predictions) is anyone's guess.
\item
  We are 95\% certain that they will add on between 295 and 1731
  additional jobs on average year-over-year. Our predictive precision
  here is not that great.
\item
  our p-value indicates that with our alpha of 0.05, and a p-value of
  0.0336, we can conclude that on average they are indeed growing their
  workforce.
\item
  Growth is growth, but maybe I should hold off on applying for a job
  next year.
\end{itemize}

    \hypertarget{which-departments-are-experiencing-positive-average-growth}{%
\section{Which Departments Are Experiencing Positive Average
Growth}\label{which-departments-are-experiencing-positive-average-growth}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{13}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Break down data by dept}
\PY{n}{depts} \PY{o}{=} \PY{n+nf}{split}\PY{p}{(}\PY{n}{SAL}\PY{p}{,} \PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{agency}\PY{p}{)}

\PY{c+c1}{\PYZsh{} use dept data, break them down by year and make a fit line for all of them}
\PY{n}{find\PYZus{}best\PYZus{}depts} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{depts}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{data} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{Dept}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{Growth}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{p}{)}\PY{p}{)}
    \PY{n+nf}{for }\PY{p}{(}\PY{n}{dept} \PY{n}{in} \PY{n}{depts}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{by\PYZus{}year} \PY{o}{=} \PY{n+nf}{split}\PY{p}{(}\PY{n}{dept}\PY{p}{,} \PY{n}{dept}\PY{o}{\PYZdl{}}\PY{n}{fiscal.year}\PY{p}{)}
        \PY{n}{jobs\PYZus{}by\PYZus{}year} \PY{o}{=} \PY{n+nf}{employees}\PY{p}{(}\PY{n}{by\PYZus{}year}\PY{p}{)}
        \PY{n}{df} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{year}\PY{o}{=}\PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{jobs\PYZus{}by\PYZus{}year}\PY{p}{)}\PY{p}{,} \PY{n}{jobs} \PY{o}{=} \PY{n}{jobs\PYZus{}by\PYZus{}year}\PY{p}{)}
        \PY{n+nf}{if }\PY{p}{(}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{o}{\PYZgt{}}\PY{l+m}{1}\PY{p}{)}\PY{p}{\PYZob{}}
            \PY{n}{fit} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{jobs}\PY{o}{\PYZti{}}\PY{n}{year}\PY{p}{,} \PY{n}{df}\PY{p}{)}
            \PY{n}{summ} \PY{o}{=} \PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit}\PY{p}{)}
            \PY{n}{b1} \PY{o}{=} \PY{n}{summ}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m}{2}\PY{p}{,}\PY{l+m}{1}\PY{p}{]}
            \PY{n}{pval} \PY{o}{=} \PY{n}{summ}\PY{o}{\PYZdl{}}\PY{n}{coefficients}\PY{p}{[}\PY{l+m}{2}\PY{p}{,}\PY{l+m}{4}\PY{p}{]}
            \PY{c+c1}{\PYZsh{} only include positive growth that we\PYZsq{}re confident in}
            \PY{n+nf}{if }\PY{p}{(}\PY{o}{!}\PY{n+nf}{is.nan}\PY{p}{(}\PY{n}{pval}\PY{p}{)} \PY{o}{\PYZam{}} \PY{n}{pval} \PY{o}{\PYZlt{}=} \PY{l+m}{0.05} \PY{o}{\PYZam{}} \PY{n}{b1} \PY{o}{\PYZgt{}} \PY{l+m}{0}\PY{p}{)}\PY{p}{\PYZob{}}
                \PY{n}{data}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{o}{+} \PY{l+m}{1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{dept}\PY{p}{[}\PY{l+m}{1}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}\PY{p}{,} \PY{n}{b1}\PY{p}{)}
            \PY{p}{\PYZcb{}}
        \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
    \PY{n}{data}
\PY{p}{\PYZcb{}}
\PY{n}{growing\PYZus{}depts} \PY{o}{=} \PY{n+nf}{find\PYZus{}best\PYZus{}depts}\PY{p}{(}\PY{n}{depts}\PY{p}{)}
\PY{n}{growing\PYZus{}depts} \PY{o}{=} \PY{n}{growing\PYZus{}depts}\PY{p}{[}\PY{n+nf}{order}\PY{p}{(}\PY{n}{growing\PYZus{}depts}\PY{o}{\PYZdl{}}\PY{n}{Growth}\PY{p}{)}\PY{p}{,}\PY{p}{]}
\PY{n+nf}{tail}\PY{p}{(}\PY{n}{growing\PYZus{}depts}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    A data.frame: 6 × 2
\begin{tabular}{r|ll}
  & Dept & Growth\\
  & <chr> & <dbl>\\
\hline
	9 & HOUSING \& COMM SRVCS, DEPT OF &  19.000\\
	1 & ADMINISTRATIVE SRVCS, DEPT OF &  19.750\\
	18 & POLICE, OREGON STATE          &  19.905\\
	4 & EDUCATION, DEPT OF            &  26.940\\
	5 & EMPLOYMENT DEPT               & 157.702\\
	10 & HUMAN SERVICES, DEPARTMENT OF & 429.655\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{14}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nf}{barplot}\PY{p}{(}\PY{n}{growing\PYZus{}depts}\PY{o}{\PYZdl{}}\PY{n}{Growth}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkseagreen\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Growth seems to be heavily concentrated almost exponentially in certain
departments

\hypertarget{looking-at-jobs-im-willing-and-qualified-to-work}{%
\section{Looking At Jobs I'm Willing And Qualified To
Work}\label{looking-at-jobs-im-willing-and-qualified-to-work}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{15}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Extract the jobs I\PYZsq{}m qualified for and am willing to do}
\PY{n}{QUAL} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{SAL}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{ACCOUNTING TECH\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{ADMINISTRATIVE ANALYST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{APPLICATIONS DEVELOPER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{APPLICATIONS SYSTEMS MANAGER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{ARCHIVIST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{ASSOCIATE IN GEOLOGY\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{CLERICAL ASSISTANT\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{COMPUTER SVCS COORDINATOR\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{CONTRACT MANAGER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{CUSTODIAN\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{CUSTOMER ENGAGEMENT MANAGER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{DATA ENTRY CONTROL TECH\PYZsq{}⋯\PYZsq{}REHABILITATION THERAPY PRG MGR\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{RESEARCH \PYZam{} IT DIRECTOR\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{RESEARCH ANALYST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SCIENTIFIC INSTRUMENT TECH\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SENIOR APPLICATIONS DEVELOPER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SENIOR CONTRACT ANALYST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SENIOR IT PROJECT MANAGER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SYSTEMS \PYZam{} PROGRAMMING SUPERVISOR\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SYSTEMS \PYZam{} PROGRAMMING SUPV\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SYSTEMS ADMINISTRATOR\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{SYSTEMS ANALYST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{TRANSPORTATION TELECOMMUNICATIONS SPECIALIST\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{TRUCK DRIVER\PYZdq{}}\PY{o}{|}\PY{n}{GEN\PYZus{}CLASS} \PY{o}{==} \PY{l+s}{\PYZdq{}}\PY{l+s}{WORD PROCESSING TECH\PYZdq{}}
\PY{n}{QUAL} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n}{SAL}\PY{p}{[}\PY{n}{QUAL}\PY{p}{,}\PY{p}{]}

\PY{c+c1}{\PYZsh{} detach(SAL)}
\PY{n+nf}{attach}\PY{p}{(}\PY{n}{QUAL}\PY{p}{)}

\PY{c+c1}{\PYZsh{} How much data does that leave me, and what does it look like?}
\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{Rows of interesting data :\PYZdq{}}\PY{p}{,} \PY{n+nf}{nrow}\PY{p}{(}\PY{n}{QUAL}\PY{p}{)}\PY{p}{)}

\PY{n}{QUAL}\PY{p}{[}\PY{l+m}{10}\PY{o}{:}\PY{l+m}{18}\PY{p}{,} \PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
The following object is masked \_by\_ .GlobalEnv:

    classification


The following objects are masked from SAL:

    agency, agency.1, classification, fiscal.year, full.part.time,
    salary.annual, service.type


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
Rows of interesting data : 6068
    \end{Verbatim}

    A data.frame: 9 × 8
\begin{tabular}{r|llllllll}
  & fiscal.year & agency & classification & salary.annual & full.part.time & service.type & agency.1 & gen\_class\\
  & <int> & <chr> & <chr> & <int> & <chr> & <chr> & <int> & <chr>\\
\hline
	300 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 2 & 33072 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	301 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 2 & 34476 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	302 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 2 & 41454 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	303 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 2 & 43284 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	304 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 2 & 45448 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	305 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 3 & 34476 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	306 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 3 & 34476 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	307 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 3 & 37668 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
	308 & 2015 & ADMINISTRATIVE SRVCS, DEPT OF & ACCOUNTING TECH 3 & 37668 & FULL TIME & REPRESENTED & 10700 & ACCOUNTING TECH\\
\end{tabular}


    
    \hypertarget{how-many-new-positions-that-i-might-be-interested-in-do-i-expect-to-be-added-next-year}{%
\section{How Many New Positions That I Might Be Interested In Do I
Expect To Be Added Next
Year?}\label{how-many-new-positions-that-i-might-be-interested-in-do-i-expect-to-be-added-next-year}}

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{16}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Estimate of overall job growth in the jobs I\PYZsq{}m interested in}
\PY{n}{years} \PY{o}{=} \PY{n+nf}{split}\PY{p}{(}\PY{n}{QUAL}\PY{p}{,} \PY{n}{fiscal.year}\PY{p}{)}
\PY{n}{emp} \PY{o}{=} \PY{n+nf}{employees}\PY{p}{(}\PY{n}{years}\PY{p}{)}
\PY{n}{emp} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{Year}\PY{o}{=}\PY{l+m}{1}\PY{o}{:}\PY{n+nf}{length}\PY{p}{(}\PY{n}{emp}\PY{p}{)}\PY{l+m}{+2014}\PY{p}{,} \PY{n}{Jobs}\PY{o}{=}\PY{n}{emp}\PY{p}{)}
\PY{n}{fit} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{Jobs}\PY{o}{\PYZti{}}\PY{n}{Year}\PY{p}{,} \PY{n}{emp}\PY{p}{)}
\PY{n+nf}{summary}\PY{p}{(}\PY{n}{fit}\PY{p}{)}

\PY{n+nf}{plot}\PY{p}{(}\PY{n}{emp}\PY{p}{,} \PY{n}{xlab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Year\PYZdq{}}\PY{p}{,} \PY{n}{ylab}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{Jobs\PYZdq{}}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkblue\PYZdq{}}\PY{p}{)}
\PY{n+nf}{abline}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkviolet\PYZdq{}}\PY{p}{)}


\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{I estimate that there will be\PYZdq{}}\PY{p}{,} \PY{n+nf}{as.integer}\PY{p}{(}\PY{n+nf}{predict}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{Year}\PY{o}{=}\PY{l+m}{2022}\PY{p}{)}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{emp}\PY{p}{[}\PY{n}{emp}\PY{o}{\PYZdl{}}\PY{n}{Year}\PY{o}{==}\PY{l+m}{2022}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{new jobs I can apply to next year.\PYZdq{}}\PY{p}{)}

\PY{n}{fit}

\PY{n+nf}{cat}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}nWith a 90\PYZpc{} confidence interval of the average yearly growh between [\PYZdq{}}\PY{p}{,} \PY{n+nf}{confint}\PY{p}{(}\PY{n}{fit}\PY{p}{,} \PY{n}{level}\PY{o}{=}\PY{l+m}{0.90}\PY{p}{)}\PY{p}{[}\PY{l+m}{2}\PY{p}{,}\PY{p}{]}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{]\PYZdq{}}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    
    \begin{Verbatim}[commandchars=\\\{\}]

Call:
lm(formula = Jobs \textasciitilde{} Year, data = emp)

Residuals:
   Min     1Q Median     3Q    Max 
-35.71  -4.52   3.43  10.17  19.33 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)  
(Intercept) -20483.81    6013.27   -3.41    0.014 *
Year            10.52       2.98    3.53    0.012 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 19.3 on 6 degrees of freedom
Multiple R-squared:  0.675,	Adjusted R-squared:  0.621 
F-statistic: 12.5 on 1 and 6 DF,  p-value: 0.0123

    \end{Verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
I estimate that there will be -2 new jobs I can apply to next year.
    \end{Verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]

Call:
lm(formula = Jobs \textasciitilde{} Year, data = emp)

Coefficients:
(Intercept)         Year  
   -20483.8         10.5  

    \end{Verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]

With a 90\% confidence interval of the average yearly growh between [ 4.7349
16.313 ]
    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_29_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{17}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Lets look and see if there is any predicted growth in the kind of jobs I\PYZsq{}m insterested in.}
\PY{n}{gen\PYZus{}class} \PY{o}{=} \PY{n}{QUAL}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class}

\PY{n+nf}{length}\PY{p}{(}\PY{n+nf}{unique}\PY{p}{(}\PY{n}{gen\PYZus{}class}\PY{p}{)}\PY{p}{)}

\PY{n}{growth} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{job}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{,} \PY{n}{new.jobs.2023}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{,} \PY{n}{average.growth.rate}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{,} \PY{n}{p.val}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{)}

\PY{n}{jobs\PYZus{}by\PYZus{}year} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{year}\PY{o}{=}\PY{n}{QUAL}\PY{o}{\PYZdl{}}\PY{n}{fiscal.year}\PY{p}{,} \PY{n}{job}\PY{o}{=}\PY{n}{QUAL}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class}\PY{p}{)}

\PY{n+nf}{for }\PY{p}{(}\PY{n}{job} \PY{n}{in} \PY{n+nf}{unique}\PY{p}{(}\PY{n}{gen\PYZus{}class}\PY{p}{)}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{job\PYZus{}y} \PY{o}{=} \PY{n}{jobs\PYZus{}by\PYZus{}year}\PY{p}{[}\PY{n}{gen\PYZus{}class}\PY{o}{==}\PY{n}{job}\PY{p}{,}\PY{p}{]}
    \PY{n}{df} \PY{o}{=} \PY{n+nf}{as.data.frame}\PY{p}{(}\PY{n+nf}{table}\PY{p}{(}\PY{n}{job\PYZus{}y}\PY{o}{\PYZdl{}}\PY{n}{year}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} Get a dataframe that counts of a particular for each year}
    \PY{n+nf}{names}\PY{p}{(}\PY{n}{df}\PY{p}{)} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{c}\PY{p}{(}\PY{l+s}{\PYZdq{}}\PY{l+s}{year\PYZdq{}}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{count\PYZdq{}}\PY{p}{)}
    \PY{n+nf}{if }\PY{p}{(}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{df}\PY{p}{)} \PY{o}{==} \PY{l+m}{8}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{year} \PY{o}{=} \PY{n+nf}{as.numeric}\PY{p}{(}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{year}\PY{p}{)}
        \PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{year} \PY{o}{=} \PY{p}{(}\PY{l+m}{2014}\PY{p}{)} \PY{o}{+} \PY{l+m}{1}\PY{o}{:}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{df}\PY{p}{)}  \PY{c+c1}{\PYZsh{} adjust indicies so they line up with the data\PYZsq{}s year}
        
        \PY{n}{model} \PY{o}{=} \PY{n+nf}{lm}\PY{p}{(}\PY{n}{count} \PY{o}{\PYZti{}} \PY{n}{year}\PY{p}{,} \PY{n}{data}\PY{o}{=}\PY{n}{df}\PY{p}{)}
        \PY{n}{sum} \PY{o}{=} \PY{n+nf}{summary}\PY{p}{(}\PY{n}{model}\PY{p}{)}
        \PY{n}{coef} \PY{o}{=} \PY{n+nf}{summary}\PY{p}{(}\PY{n}{model}\PY{p}{)}\PY{o}{\PYZdl{}}\PY{n}{coefficients}
        
        \PY{n}{new\PYZus{}jobs\PYZus{}predicted} \PY{o}{=} \PY{n+nf}{predict}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{year}\PY{o}{=}\PY{l+m}{2023}\PY{p}{)}\PY{p}{)}\PY{o}{\PYZhy{}} \PY{n}{df}\PY{p}{[}\PY{n}{df}\PY{o}{\PYZdl{}}\PY{n}{year}\PY{o}{==}\PY{l+m}{2022}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}
        \PY{n}{growth\PYZus{}coefficient} \PY{o}{=} \PY{n}{coef}\PY{p}{[}\PY{l+m}{2}\PY{p}{,} \PY{l+m}{1}\PY{p}{]}  \PY{c+c1}{\PYZsh{} B1}
        \PY{n}{p} \PY{o}{=} \PY{n}{coef}\PY{p}{[}\PY{l+m}{2}\PY{p}{,} \PY{l+m}{4}\PY{p}{]}

        
        \PY{c+c1}{\PYZsh{} only add positive growth that we\PYZsq{}re statistially confident is occuring}
        \PY{n+nf}{if }\PY{p}{(}\PY{n}{p} \PY{o}{\PYZlt{}=} \PY{l+m}{0.05}\PY{o}{\PYZam{}} \PY{n}{growth\PYZus{}coefficient} \PY{o}{\PYZgt{}} \PY{l+m}{0}\PY{p}{)}\PY{p}{\PYZob{}}
            \PY{n}{l} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{job}\PY{p}{,} \PY{n}{new\PYZus{}jobs\PYZus{}predicted}\PY{p}{,} \PY{n}{growth\PYZus{}coefficient}\PY{p}{,} \PY{n}{p}\PY{p}{)}
            \PY{n}{growth}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{growth}\PY{p}{)}\PY{l+m}{+1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n}{l}
        \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
    

\PY{p}{\PYZcb{}}
\PY{n}{growth}
\end{Verbatim}
\end{tcolorbox}

    23

    
    A data.frame: 2 × 4
\begin{tabular}{r|llll}
  & job & new.jobs.2023 & average.growth.rate & p.val\\
  & <chr> & <dbl> & <dbl> & <dbl>\\
\hline
	1 & CUSTODIAN        &  -1.750 & 1.5833 & 0.026284\\
	2 & RESEARCH ANALYST & -18.036 & 5.3810 & 0.033705\\
\end{tabular}


    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{ }{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]

\end{Verbatim}
\end{tcolorbox}

    It looks like I'm confident that they'll be looking for custodians and
research analysts at some point. But because 2022 seems to be such an
outlier, my model expects some sort of regression-to-the-mean. So
according to the data and my statistical models, I shouldn't be planning
to get a job next year.

\hypertarget{which-jobs-that-i-could-do-have-the-most-fair-pay}{%
\section{Which Jobs That I Could Do Have The Most Fair
Pay?}\label{which-jobs-that-i-could-do-have-the-most-fair-pay}}

looking at the data, there are many jobs descriptions that are followed
by numbers. I take this to mean that you can be promoted from one level
to another. If I did one of these jobs (one's I'd be willing to do),
it's important to me that I'm working with people that are being paid
fairly---it makes for a less hostile work enviornment. In this case,
I'll settle for the qualifyer that the salaries in that job are normally
distributed.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{18}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Filter for jobs that end in numbers that I can run my analysis on}
\PY{c+c1}{\PYZsh{} We\PYZsq{}ll measure across all years and all departments, It\PYZsq{}s important that people doing the same job}
\PY{c+c1}{\PYZsh{} in different departments are paid with around the same distribution.}

\PY{n}{q} \PY{o}{=} \PY{n}{QUAL}\PY{p}{[}\PY{n+nf}{str\PYZus{}detect}\PY{p}{(}\PY{n}{QUAL}\PY{o}{\PYZdl{}}\PY{n}{classification}\PY{p}{,} \PY{l+s}{\PYZdq{}}\PY{l+s}{\PYZbs{}\PYZbs{}d+\PYZdl{}\PYZdq{}}\PY{p}{)}\PY{p}{,}\PY{p}{]}
\PY{n}{frequencies} \PY{o}{=} \PY{n+nf}{as.data.frame}\PY{p}{(}\PY{n+nf}{table}\PY{p}{(}\PY{n}{q}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class}\PY{p}{)}\PY{p}{)}

\PY{c+c1}{\PYZsh{} We\PYZsq{}ll filter out any jobs that have less than 30 measurements to choose from}
\PY{n}{jobs} \PY{o}{=} \PY{n}{frequencies}\PY{p}{[}\PY{n}{frequencies}\PY{o}{\PYZdl{}}\PY{n}{Freq} \PY{o}{\PYZgt{}=} \PY{l+m}{30}\PY{p}{,}\PY{l+m}{1}\PY{p}{]}

\PY{n}{samp10} \PY{o}{\PYZlt{}\PYZhy{}} \PY{n+nf}{function}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{dept\PYZus{}names}\PY{p}{)}\PY{p}{\PYZob{}}  \PY{c+c1}{\PYZsh{} take 10 salary samples from each job}
    \PY{n}{new} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{job}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{,} \PY{n}{sample}\PY{o}{=}\PY{n+nf}{numeric}\PY{p}{(}\PY{l+m}{0}\PY{p}{)}\PY{p}{)}
    \PY{n+nf}{for }\PY{p}{(}\PY{n}{name} \PY{n}{in} \PY{n}{dept\PYZus{}names}\PY{p}{)}\PY{p}{\PYZob{}}
        \PY{n}{salaries} \PY{o}{=} \PY{n}{data}\PY{p}{[}\PY{n}{data}\PY{o}{\PYZdl{}}\PY{n}{gen\PYZus{}class} \PY{o}{==} \PY{n}{name}\PY{p}{,}\PY{l+m}{4}\PY{p}{]}
        \PY{n+nf}{for}\PY{p}{(}\PY{n}{x} \PY{n}{in} \PY{l+m}{1}\PY{o}{:}\PY{l+m}{25}\PY{p}{)}\PY{p}{\PYZob{}}
            \PY{n}{r} \PY{o}{=} \PY{n+nf}{floor}\PY{p}{(}\PY{n+nf}{runif}\PY{p}{(}\PY{l+m}{1}\PY{p}{,} \PY{n}{min}\PY{o}{=}\PY{l+m}{1}\PY{p}{,} \PY{n}{max}\PY{o}{=}\PY{n+nf}{length}\PY{p}{(}\PY{n}{salaries}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            \PY{n}{row} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{name}\PY{p}{,} \PY{n}{salaries}\PY{p}{[}\PY{n}{r}\PY{p}{]}\PY{p}{)}
            \PY{n}{salaries} \PY{o}{=} \PY{n}{salaries}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{n}{r}\PY{p}{]}
            \PY{n}{new}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{new}\PY{p}{)}\PY{l+m}{+1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n}{row}
        \PY{p}{\PYZcb{}}
    \PY{p}{\PYZcb{}}
    \PY{n}{new}
\PY{p}{\PYZcb{}}

\PY{c+c1}{\PYZsh{} We\PYZsq{}ll take a look at the histograms and q\PYZhy{}q graphs of the jobs I can analyse, just to see how normal they appear.}
\PY{n}{samples} \PY{o}{=} \PY{n+nf}{samp10}\PY{p}{(}\PY{n}{QUAL}\PY{p}{,} \PY{n}{jobs}\PY{p}{)}
\PY{n+nf}{for }\PY{p}{(}\PY{n}{job} \PY{n}{in} \PY{n}{jobs}\PY{p}{[}\PY{l+m}{1}\PY{o}{:}\PY{l+m}{2}\PY{p}{]}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{smp} \PY{o}{=} \PY{n}{samples}\PY{p}{[}\PY{n}{samples}\PY{o}{\PYZdl{}}\PY{n}{job}\PY{o}{==}\PY{n}{job}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}
    \PY{n+nf}{hist}\PY{p}{(}\PY{n}{smp}\PY{p}{,} \PY{n}{main}\PY{o}{=}\PY{n}{job}\PY{p}{,} \PY{n}{breaks}\PY{o}{=}\PY{l+m}{20}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkseagreen\PYZdq{}}\PY{p}{)}
    \PY{n+nf}{qqnorm}\PY{p}{(}\PY{n}{smp}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkblue\PYZdq{}}\PY{p}{)}
    \PY{n+nf}{qqline}\PY{p}{(}\PY{n}{smp}\PY{p}{,} \PY{n}{col}\PY{o}{=}\PY{l+s}{\PYZdq{}}\PY{l+s}{darkviolet\PYZdq{}}\PY{p}{)}
\PY{p}{\PYZcb{}}
\end{Verbatim}
\end{tcolorbox}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_33_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_33_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_33_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{Project_files/Project_33_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{19}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} let\PYZsq{}s get some stats on this: according to shapiro\PYZhy{}wilk, which job is closest to a normal distribution}
\PY{c+c1}{\PYZsh{} re\PYZhy{}using the random samples from above}

\PY{n}{norm\PYZus{}measures} \PY{o}{=} \PY{n+nf}{data.frame}\PY{p}{(}\PY{n}{job}\PY{o}{=}\PY{n+nf}{character}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{shapiro.p} \PY{o}{=} \PY{n+nf}{numeric}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\PY{n+nf}{for }\PY{p}{(}\PY{n}{job} \PY{n}{in} \PY{n}{jobs}\PY{p}{)}\PY{p}{\PYZob{}}
    \PY{n}{smp} \PY{o}{=} \PY{n}{samples}\PY{p}{[}\PY{n}{samples}\PY{o}{\PYZdl{}}\PY{n}{job}\PY{o}{==}\PY{n}{job}\PY{p}{,}\PY{l+m}{2}\PY{p}{]}
    \PY{n}{shap} \PY{o}{=} \PY{n+nf}{shapiro.test}\PY{p}{(}\PY{n}{smp}\PY{p}{)}
    \PY{n}{norm\PYZus{}measures}\PY{p}{[}\PY{n+nf}{nrow}\PY{p}{(}\PY{n}{norm\PYZus{}measures}\PY{p}{)}\PY{l+m}{+1}\PY{p}{,}\PY{p}{]} \PY{o}{=} \PY{n+nf}{list}\PY{p}{(}\PY{n}{job}\PY{p}{,} \PY{n}{shap}\PY{o}{\PYZdl{}}\PY{n}{p.value}\PY{p}{)}
\PY{p}{\PYZcb{}}
\PY{n}{norm\PYZus{}measures}\PY{p}{[}\PY{n+nf}{order}\PY{p}{(}\PY{n}{norm\PYZus{}measures}\PY{o}{\PYZdl{}}\PY{n}{shapiro.p}\PY{p}{,} \PY{n}{decreasing}\PY{o}{=}\PY{n+nb+bp}{T}\PY{p}{)}\PY{p}{,}\PY{p}{]}
\end{Verbatim}
\end{tcolorbox}

    A data.frame: 6 × 2
\begin{tabular}{r|ll}
  & job & shapiro.p\\
  & <chr> & <dbl>\\
\hline
	4 & RESEARCH ANALYST                             & 0.8094928\\
	1 & ACCOUNTING TECH                              & 0.6414775\\
	3 & ASSOCIATE IN GEOLOGY                         & 0.4636912\\
	6 & TRUCK DRIVER                                 & 0.3448663\\
	2 & ARCHIVIST                                    & 0.2627029\\
	5 & TRANSPORTATION TELECOMMUNICATIONS SPECIALIST & 0.0069487\\
\end{tabular}


    
    Well, it looks like \textbf{most} of the positions that I'm interested
have strong evidence in favor of normality. Under my definition of
egalitarianism, it looks like I'd be happy at any of these jobs except
as a transportation telecom specialist.


    % Add a bibliography block to the postdoc
    
    
    
\end{document}
